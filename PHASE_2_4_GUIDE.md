# Phase 2.4: AI Transcription Integration (Google Cloud Speech-to-Text)

**Status:** ğŸš€ In Progress  
**Started:** December 20, 2025  
**Provider:** Google Cloud Speech-to-Text API

---

## ğŸ¯ Objective

Connect live audio streaming from frontend microphone â†’ WebSocket â†’ Google Cloud STT â†’ Real-time transcription display.

**Expected Latency:** <500ms end-to-end (audio capture â†’ transcription â†’ display)

---

## ğŸ“‹ Setup Checklist

### Step 1: Google Cloud Project Setup (15 mins)

#### 1.1 Create GCP Project
```bash
# Go to: https://console.cloud.google.com/
# Click "Select a project" â†’ "New Project"
# Name: "parleap-ai" (or your choice)
# Click "Create"
```

#### 1.2 Enable Speech-to-Text API
```bash
# In GCP Console:
# Navigate to: APIs & Services â†’ Library
# Search: "Cloud Speech-to-Text API"
# Click "Enable"
```

#### 1.3 Create Service Account
```bash
# Navigate to: IAM & Admin â†’ Service Accounts
# Click "Create Service Account"
# Name: "parleap-stt-service"
# Role: "Cloud Speech Client" (or "Cloud Speech Administrator")
# Click "Create and Continue" â†’ "Done"
```

#### 1.4 Generate API Key
```bash
# Click on the service account you just created
# Go to "Keys" tab
# Click "Add Key" â†’ "Create new key"
# Choose JSON format
# Download the JSON file
# Save it as: backend/config/google-cloud-credentials.json
```

âš ï¸ **IMPORTANT**: Add to `.gitignore`:
```
backend/config/google-cloud-credentials.json
```

#### 1.5 Set Environment Variable
Add to `backend/.env`:
```env
GOOGLE_APPLICATION_CREDENTIALS=./config/google-cloud-credentials.json
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Audio Chunks   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Binary Audio   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’  â”‚  WebSocket  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚  STT Service â”‚
â”‚ (Microphone)â”‚   (Base64)      â”‚   Handler   â”‚   (Buffer)      â”‚ (Google API) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                        â”‚
                                                                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  TRANSCRIPT     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   Transcription  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend   â”‚ â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚  WebSocket  â”‚ â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚ Google Cloud â”‚
â”‚  (Display)  â”‚    _UPDATE      â”‚   Handler   â”‚    (Text)        â”‚  Speech API  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ File Structure

```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ sttService.ts          âœ¨ NEW - Google Cloud STT integration
â”‚   â”‚   â””â”€â”€ eventService.ts        (existing)
â”‚   â”œâ”€â”€ websocket/
â”‚   â”‚   â””â”€â”€ handler.ts             ğŸ”§ UPDATE - Add STT integration
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â””â”€â”€ websocket.ts           ğŸ”§ UPDATE - Add TRANSCRIPT_UPDATE type
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ google-cloud-credentials.json  ğŸ” (gitignored)
â”œâ”€â”€ .env                           ğŸ”§ UPDATE - Add GOOGLE_APPLICATION_CREDENTIALS
â””â”€â”€ package.json                   ğŸ”§ UPDATE - Add @google-cloud/speech
```

---

## ğŸ”§ Implementation Steps

### Step 2: Install Dependencies
```bash
cd backend
npm install @google-cloud/speech
```

### Step 3: Create STT Service
File: `backend/src/services/sttService.ts`
- Initialize Google Cloud Speech client
- Create streaming recognition config (16kHz, mono, LINEAR16)
- Handle audio chunks (convert base64 â†’ Buffer)
- Return transcription results with confidence scores
- Error handling and reconnection logic

### Step 4: Update WebSocket Types
File: `backend/src/types/websocket.ts`
- Add `TRANSCRIPT_UPDATE` server message type
- Include fields: `text`, `isFinal`, `confidence`

### Step 5: Integrate into WebSocket Handler
File: `backend/src/websocket/handler.ts`
- Route `AUDIO_DATA` messages to STT service
- Send `TRANSCRIPT_UPDATE` messages back to client
- Track partial vs. final transcriptions

### Step 6: Frontend Display
File: `frontend/components/operator/GhostText.tsx`
- Display live transcription text
- Show confidence meter
- Differentiate partial (gray) vs. final (white) text

---

## ğŸ§ª Testing Plan

### Unit Tests
- [ ] STT service can connect to Google API
- [ ] Audio buffer conversion (base64 â†’ Buffer) works
- [ ] Handles API errors gracefully
- [ ] Reconnects on connection loss

### Integration Tests
- [ ] WebSocket sends AUDIO_DATA correctly
- [ ] Backend forwards to Google Cloud
- [ ] TRANSCRIPT_UPDATE received by frontend
- [ ] End-to-end latency <500ms

### Manual Testing
- [ ] Speak into microphone â†’ see transcription
- [ ] Test with background noise
- [ ] Test with different accents
- [ ] Test rapid speech vs. slow speech

---

## ğŸ¯ Success Criteria

âœ… Audio chunks stream from frontend â†’ backend  
âœ… Google Cloud STT receives and processes audio  
âœ… Transcription appears in real-time (<500ms)  
âœ… Confidence scores displayed accurately  
âœ… System handles errors gracefully (API failures, network issues)  
âœ… No memory leaks with long-running sessions  

---

## ğŸ“Š Expected Performance

| Metric | Target | Notes |
|--------|--------|-------|
| Audio Capture | 1000ms chunks | MediaRecorder config |
| WebSocket Latency | <10ms | Already achieved |
| STT Processing | 200-300ms | Google Cloud typical |
| Total End-to-End | <500ms | Capture â†’ Display |
| Accuracy | >90% | Clear audio, standard English |

---

## ğŸš¨ Common Issues & Solutions

### Issue: "Application Default Credentials not found"
**Solution:** Ensure `GOOGLE_APPLICATION_CREDENTIALS` env var points to correct JSON file

### Issue: "Audio encoding not supported"
**Solution:** Verify audio format: LINEAR16, 16kHz, mono

### Issue: High latency (>1 second)
**Solution:** Check chunk size (reduce to 500ms), verify network connection

### Issue: Low transcription accuracy
**Solution:** Improve microphone quality, reduce background noise, adjust sample rate

---

## ğŸ’° Cost Estimation

**Google Cloud Speech-to-Text Pricing:**
- $0.024 per 15 seconds (standard models)
- $0.048 per 15 seconds (enhanced models)

**Example Usage:**
- 1-hour service: ~$5.76 (standard) or ~$11.52 (enhanced)
- Monthly (50 hours): ~$288 (standard) or ~$576 (enhanced)

**Cost Optimization:**
- Use standard models for most cases
- Only upgrade to enhanced for critical events
- Cache/reuse transcriptions where possible

---

## ğŸ” Security Considerations

1. **API Keys**: Never commit credentials to Git
2. **Service Account**: Use least-privilege roles
3. **Rate Limiting**: Implement to prevent abuse
4. **Audio Data**: Don't log/store sensitive audio without consent
5. **HTTPS**: Always use secure connections in production

---

## ğŸ“š Resources

- [Google Cloud Speech-to-Text Docs](https://cloud.google.com/speech-to-text/docs)
- [Streaming Recognition Guide](https://cloud.google.com/speech-to-text/docs/streaming-recognize)
- [Best Practices](https://cloud.google.com/speech-to-text/docs/best-practices)
- [Pricing Calculator](https://cloud.google.com/products/calculator)

---

**Next Steps:** Follow the implementation in order (Setup â†’ Install â†’ Build â†’ Test)

